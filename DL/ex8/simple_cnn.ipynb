{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:54:54.099956Z",
     "start_time": "2025-12-07T20:54:54.093745Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 2, 3])\n",
      "torch.Size([4, 1, 2, 3])\n",
      "torch.Size([4, 1, 2, 2])\n",
      "tensor([[[[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.3567],\n",
      "          [0.3209, 0.5673]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000],\n",
      "          [0.5480, 0.5480]]],\n",
      "\n",
      "\n",
      "        [[[0.3254, 0.3254],\n",
      "          [0.0825, 0.3678]]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 2), stride=(1, 1), padding=0)\n",
    "        # Activation function after convolution layer\n",
    "        self.relu = nn.ReLU()\n",
    "        # Max Pooling Layer\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)) # no hyperparameter channels anymore\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        conv1out = self.conv1(input)\n",
    "        print(conv1out.shape)\n",
    "        relu1 = self.relu(conv1out)\n",
    "        print(relu1.shape)\n",
    "        max1out = self.max1(relu1)\n",
    "        print(max1out.shape)\n",
    "        return max1out\n",
    "\n",
    "# batch_size: 4\n",
    "# H: 3\n",
    "# W: 4\n",
    "# Conv2D: (N, C, H, W) N -> batch_size, C -> channels, H -> height, W -> width\n",
    "input = torch.randn((4, 1, 3, 4))\n",
    "simple_cnn = SimpleCNN()\n",
    "output = simple_cnn(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a369a9b23976de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:54:54.119308Z",
     "start_time": "2025-12-07T20:54:54.116588Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiChannelCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # input and output channels must be tuned because they are hyper-parameters\n",
    "        self.conv1=nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1), padding=0)\n",
    "        # Activation function after convolution layer\n",
    "        self.relu = nn.ReLU()\n",
    "        # Max Pooling Layer\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)) # no hyperparameter channels anymore\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        conv1out = self.conv1(input)\n",
    "        print(conv1out.shape)\n",
    "        relu1 = self.relu(conv1out)\n",
    "        print(relu1.shape)\n",
    "        max1out = self.max1(relu1)\n",
    "        print(max1out.shape)\n",
    "        return max1out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71a9b7c9e282872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:54:54.128750Z",
     "start_time": "2025-12-07T20:54:54.125106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 2, 3])\n",
      "torch.Size([4, 6, 2, 3])\n",
      "torch.Size([4, 6, 2, 2])\n",
      "tensor([[[[0.6714, 0.6714],\n",
      "          [0.0000, 1.9236]],\n",
      "\n",
      "         [[1.7209, 1.7209],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7667, 0.8927],\n",
      "          [0.0000, 0.4141]],\n",
      "\n",
      "         [[0.5412, 0.5412],\n",
      "          [0.5412, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [1.0475, 1.0028]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.6448, 0.8287]]],\n",
      "\n",
      "\n",
      "        [[[0.4833, 0.4833],\n",
      "          [0.6043, 0.6043]],\n",
      "\n",
      "         [[0.3296, 0.3296],\n",
      "          [0.4693, 0.4693]],\n",
      "\n",
      "         [[0.0806, 0.7440],\n",
      "          [0.3055, 0.6293]],\n",
      "\n",
      "         [[0.0000, 0.1928],\n",
      "          [0.3018, 0.2471]],\n",
      "\n",
      "         [[0.3296, 0.3296],\n",
      "          [0.6285, 0.6285]],\n",
      "\n",
      "         [[0.0572, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000],\n",
      "          [0.5248, 0.4185]],\n",
      "\n",
      "         [[0.9558, 0.9558],\n",
      "          [0.1116, 0.4283]],\n",
      "\n",
      "         [[0.1920, 0.1920],\n",
      "          [0.4236, 0.4236]],\n",
      "\n",
      "         [[0.0063, 0.8014],\n",
      "          [0.7458, 0.7458]],\n",
      "\n",
      "         [[0.0000, 0.4313],\n",
      "          [1.2021, 0.1774]],\n",
      "\n",
      "         [[1.1367, 1.1367],\n",
      "          [0.5031, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1934, 0.5301],\n",
      "          [1.1753, 0.0000]],\n",
      "\n",
      "         [[0.0135, 0.3352],\n",
      "          [1.7061, 1.4274]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.6010, 0.3196]],\n",
      "\n",
      "         [[0.5502, 0.3089],\n",
      "          [0.6628, 0.4833]],\n",
      "\n",
      "         [[0.3398, 0.3398],\n",
      "          [0.1230, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0745],\n",
      "          [0.0000, 0.0000]]]], grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((4, 3, 3, 4))\n",
    "multi_channel_cnn = MultiChannelCNN()\n",
    "output = multi_channel_cnn(input)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c351785cf378f",
   "metadata": {},
   "source": [
    "- Convolutional Neural Networks expect a matrix as an input. The output is a feature map.\n",
    "- Feedforward Networks expect a vector as an input. output is a vector [number of classes]\n",
    "- Flattening is used to transform the feature map into a vector by concatenating all the elements row by row.\n",
    "- Each feature map becomes a vector concatenated into a long one dimensional vector\n",
    "- Process by CNN and feed to Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a75e767804cf27b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:54:54.141594Z",
     "start_time": "2025-12-07T20:54:54.136362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial feature map shape:  torch.Size([4, 6, 2, 2])\n",
      "96\n",
      "Second dimension:  24.0\n",
      "torch.Size([4, 6, 2, 3])\n",
      "torch.Size([4, 6, 2, 3])\n",
      "torch.Size([4, 6, 2, 2])\n",
      "torch.Size([4, 2])\n",
      "tensor([[ 0.1864, -0.1845],\n",
      "        [ 0.3665, -0.1059],\n",
      "        [ 0.4957, -0.0530],\n",
      "        [ 0.0438, -0.1378]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "feature_map = torch.randn((4, 6, 2, 2))\n",
    "print(\"Initial feature map shape: \", feature_map.shape)\n",
    "\n",
    "total = 4*6*2*2\n",
    "print(total)\n",
    "# [4 (batch size),  length of embedding calculated by dividing the total by 4,  ]\n",
    "print('Second dimension: ', total/4)\n",
    "# change the shape to [4, ?]\n",
    "\n",
    "emb = feature_map.reshape((4, 24))\n",
    "simple_emb = feature_map.reshape((4, -1)) # a cheat to force Python to do the calculation\n",
    "\n",
    "# We use flatten to connect a FFN (as predictor) to a CNN (using CNN as a feature extractor)\n",
    "\n",
    "class DogCatPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # feature extractor using multichannel CNN\n",
    "        # input and output channels must be tuned because they are hyper-parameters\n",
    "        self.conv1=nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1), padding=0)\n",
    "        # Activation function after convolution layer\n",
    "        self.relu = nn.ReLU()\n",
    "        # Max Pooling Layer\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)) # no hyperparameter channels anymore\n",
    "\n",
    "        # predictor using feedforward network\n",
    "        self.pred = nn.Linear(in_features=24, out_features=2)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # extract features\n",
    "        conv1out = self.conv1(input)\n",
    "        print(conv1out.shape)\n",
    "        relu1 = self.relu(conv1out)\n",
    "        print(relu1.shape)\n",
    "        max1out = self.max1(relu1)\n",
    "        print(max1out.shape)\n",
    "\n",
    "        # batch size is here so better not to put it here.\n",
    "        # don't hard code your variables!\n",
    "        emb = max1out.reshape((-1, 24))\n",
    "\n",
    "        # flatten max1 and feed to predictor\n",
    "        logits = self.pred(emb)\n",
    "        print(logits.shape)\n",
    "        return logits\n",
    "\n",
    "dog_cat = DogCatPredictor()\n",
    "input = torch.randn((4, 3, 3, 4))\n",
    "logits = dog_cat(input)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c476c8cc1f309128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T20:54:56.743085Z",
     "start_time": "2025-12-07T20:54:56.739472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1182, -0.4845],\n",
      "        [-0.2371, -0.4347],\n",
      "        [-0.3365, -0.4321],\n",
      "        [-0.1892, -0.2207]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleDogCat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feat_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "        )\n",
    "        self.pred = nn.Linear(in_features=24, out_features=2)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        feat = self.feat_extractor(input)\n",
    "        emb = feat.reshape((-1, 24))\n",
    "        logits = self.pred(emb)\n",
    "        return logits\n",
    "\n",
    "simple_dog_cat = SimpleDogCat()\n",
    "input = torch.randn((4, 3, 3, 4))\n",
    "logits = simple_dog_cat(input)\n",
    "print(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
