{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37af593",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "- What's `nn.Module`, how to build a model\n",
    "- Recap: what's a `CNN`\n",
    "- How to build a simple CNN in pytorch?\n",
    "    - kep concepts: channels (in_channels, out_channels), kernel_size, stride, padding: [link](https://poloclub.github.io/cnn-explainer/#:~:text=Figure%201.,occuring%20with%20each%20unique%20kernel.)\n",
    "    - How to combine CNN and Feedforward\n",
    "    - When you have a large network, how to code it?\n",
    "- What's an optimizer?\n",
    "- (Optional) An application: how to build a larger model? AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab96816",
   "metadata": {},
   "source": [
    "# Simple CNN\n",
    "\n",
    "- in_channels = out_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5b2a0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # nn.Conv2d\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(2, 2), stride=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        conv1out = self.conv1(input)\n",
    "        print('after conv1', conv1out.shape)\n",
    "        relu1 = self.relu(conv1out)\n",
    "        print('after act', relu1.shape)\n",
    "        max1out = self.max1(relu1)\n",
    "        print('after max pool', max1out.shape)\n",
    "\n",
    "        return max1out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "25d1d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conv1 torch.Size([4, 1, 2, 3])\n",
      "after act torch.Size([4, 1, 2, 3])\n",
      "after max pool torch.Size([4, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# batch_size: 4\n",
    "# H: 3\n",
    "# W: 4\n",
    "# Conv2D: (N, C, H, W) N -> batch_size, C-> channels\n",
    "input = torch.randn((4, 1, 3, 4))\n",
    "simple_cnn = SimpleCNN()\n",
    "out = simple_cnn(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30f892",
   "metadata": {},
   "source": [
    "# MultiChannelCNN\n",
    "\n",
    "- How image is represented [link](https://www.webstyleguide.com/wsg1/graphics/display_primer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "90a26dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        cnn1out = self.cnn1(input)\n",
    "        print('after cnn1', cnn1out.shape)\n",
    "        relu1 = self.relu1(cnn1out)\n",
    "        print('after act', relu1.shape)\n",
    "        max1 = self.max1(relu1)\n",
    "        print('after pool', max1.shape)\n",
    "        return max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "54165130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cnn1 torch.Size([4, 6, 2, 3])\n",
      "after act torch.Size([4, 6, 2, 3])\n",
      "after pool torch.Size([4, 6, 2, 2])\n",
      "torch.Size([4, 6, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((4, 3, 3, 4))\n",
    "multi_channel_cnn = MultiChannelCNN()\n",
    "out = multi_channel_cnn(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795204c",
   "metadata": {},
   "source": [
    "# How to combine CNN and Feedforward NN?\n",
    "\n",
    "- CNN \n",
    "    - input: a matrix [3, 4]\n",
    "    - output a feature map [2, 2]\n",
    "- FFN\n",
    "    - input (for one single sample): a vector [x], e.g., [128]\n",
    "    - output: a vector [number of classes] e.g., [2]\n",
    "- Flatten the feature map to a vector\n",
    "    - [link](https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "87360c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "feature_map = torch.randn((4, 6, 2, 2))\n",
    "print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a975855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'reshape'\n",
    "emb = feature_map.reshape((4, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e94f87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 24])\n"
     ]
    }
   ],
   "source": [
    "simple_emb = feature_map.reshape((4, -1))\n",
    "print(simple_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fdb400a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCatPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # feature_extractor\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1))\n",
    "\n",
    "        # predictor\n",
    "        self.pred = nn.Linear(in_features=24, out_features=2)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # extract features\n",
    "        cnn1out = self.cnn1(input)\n",
    "        print('after cnn1', cnn1out.shape)\n",
    "        relu1 = self.relu1(cnn1out)\n",
    "        print('after act', relu1.shape)\n",
    "        max1 = self.max1(relu1)\n",
    "        print('after pool', max1.shape)\n",
    "\n",
    "        # 48, 128\n",
    "        emb = max1.reshape((-1, 24))\n",
    "        print('after reshape', emb.shape)\n",
    "\n",
    "        logits = self.pred(emb)\n",
    "        print('after pred', logits.shape)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d9174896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cnn1 torch.Size([4, 6, 2, 3])\n",
      "after act torch.Size([4, 6, 2, 3])\n",
      "after pool torch.Size([4, 6, 2, 2])\n",
      "after reshape torch.Size([4, 24])\n",
      "after pred torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "dogcat = DogCatPredictor()\n",
    "input = torch.randn((4, 3, 3, 4))\n",
    "logits = dogcat(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb641d12",
   "metadata": {},
   "source": [
    "# Simplify the code using `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "135926ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDogCat(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feat_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(2, 2), stride=(1, 1)),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 1)),\n",
    "        )\n",
    "        \n",
    "        # predictor\n",
    "        self.pred = nn.Linear(in_features=24, out_features=2)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        feat = self.feat_extractor(input)\n",
    "\n",
    "        emb = feat.reshape((-1, 24))\n",
    "\n",
    "        logits = self.pred(emb)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1444f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dogcat = SimpleDogCat()\n",
    "input = torch.randn((4, 3, 3, 4))\n",
    "logits = simple_dogcat(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "493afab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67087a40",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "How to optimizer your models?\n",
    "1. forward\n",
    "2. backward\n",
    "3. update the weights: weight = weight - learning_rate * gradient\n",
    "\n",
    "Gradient <- backward\n",
    "\n",
    "Update <- optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "16ca6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "adam = torch.optim.Adam(simple_dogcat.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7d542c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preapre data\n",
    "inputs = torch.randn((4, 3, 3, 4))\n",
    "# dog: 0, cat: 1\n",
    "target = torch.tensor([0, 0, 1, 1], dtype=int)\n",
    "\n",
    "# model\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ebf2659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "adam.zero_grad()\n",
    "\n",
    "logits = simple_dogcat(inputs)\n",
    "loss = loss_fn(logits, target)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "\n",
    "# update\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "13547604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before step Parameter containing:\n",
      "tensor([[[[-0.1422, -0.0231],\n",
      "          [-0.0200, -0.1127]],\n",
      "\n",
      "         [[-0.1441, -0.0858],\n",
      "          [-0.1067, -0.0200]],\n",
      "\n",
      "         [[ 0.2862,  0.2100],\n",
      "          [ 0.2218, -0.1266]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2268,  0.2049],\n",
      "          [-0.1332, -0.0595]],\n",
      "\n",
      "         [[ 0.1635,  0.2513],\n",
      "          [-0.2851, -0.1297]],\n",
      "\n",
      "         [[-0.1300,  0.0317],\n",
      "          [ 0.0375,  0.2017]]],\n",
      "\n",
      "\n",
      "        [[[-0.2436, -0.0981],\n",
      "          [-0.2792,  0.0903]],\n",
      "\n",
      "         [[-0.2628, -0.1466],\n",
      "          [-0.1280, -0.0221]],\n",
      "\n",
      "         [[ 0.2268, -0.1667],\n",
      "          [-0.1990, -0.2223]]],\n",
      "\n",
      "\n",
      "        [[[-0.2615,  0.0061],\n",
      "          [ 0.1002, -0.2023]],\n",
      "\n",
      "         [[-0.2707, -0.0446],\n",
      "          [-0.1937, -0.0933]],\n",
      "\n",
      "         [[ 0.2744, -0.1357],\n",
      "          [-0.0972,  0.1548]]],\n",
      "\n",
      "\n",
      "        [[[-0.1640,  0.0444],\n",
      "          [ 0.1545, -0.1426]],\n",
      "\n",
      "         [[-0.1740, -0.1087],\n",
      "          [ 0.0618,  0.0483]],\n",
      "\n",
      "         [[-0.2546,  0.2032],\n",
      "          [-0.2771, -0.2147]]],\n",
      "\n",
      "\n",
      "        [[[-0.2595,  0.0740],\n",
      "          [ 0.2647, -0.1592]],\n",
      "\n",
      "         [[ 0.0273,  0.2046],\n",
      "          [-0.1792,  0.1455]],\n",
      "\n",
      "         [[-0.0097, -0.2254],\n",
      "          [-0.1782, -0.2779]]]], requires_grad=True)\n",
      "before step Parameter containing:\n",
      "tensor([-0.1007, -0.2246,  0.0267, -0.2773,  0.2105,  0.0510],\n",
      "       requires_grad=True)\n",
      "before step Parameter containing:\n",
      "tensor([[ 0.2026,  0.1155, -0.1665,  0.1200, -0.1522,  0.0021,  0.0333, -0.0943,\n",
      "          0.0295, -0.0433,  0.1561,  0.1407, -0.0438,  0.0247, -0.1387,  0.1399,\n",
      "         -0.0734, -0.0871, -0.0826, -0.0678,  0.1839,  0.1922, -0.1931, -0.1453],\n",
      "        [-0.0798, -0.1155,  0.1506,  0.0453,  0.0710,  0.1121,  0.0558, -0.1651,\n",
      "         -0.1933, -0.1793, -0.1649,  0.1934, -0.1214,  0.0892,  0.0705,  0.0754,\n",
      "         -0.0230, -0.1624,  0.1681, -0.1807, -0.1192, -0.0611,  0.0640, -0.0926]],\n",
      "       requires_grad=True)\n",
      "before step Parameter containing:\n",
      "tensor([-0.0416,  0.0071], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in simple_dogcat.parameters():\n",
    "    print('before step', param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "50a9ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam.zero_grad()\n",
    "# forward pass\n",
    "logits = simple_dogcat(input)\n",
    "# backward\n",
    "loss = loss_fn(logits, target)\n",
    "loss.backward()\n",
    "# update\n",
    "adam.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d0ef2f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after step Parameter containing:\n",
      "tensor([[[[  9.8578, -10.0231],\n",
      "          [-10.0200,   9.8873]],\n",
      "\n",
      "         [[  9.8559, -10.0858],\n",
      "          [  9.8933,   9.9800]],\n",
      "\n",
      "         [[ 10.2862,  10.2100],\n",
      "          [ -9.7782,   9.8734]]],\n",
      "\n",
      "\n",
      "        [[[ 10.2268,  10.2049],\n",
      "          [  9.8668, -10.0595]],\n",
      "\n",
      "         [[ 10.1632,  10.2513],\n",
      "          [  9.7149,   9.8703]],\n",
      "\n",
      "         [[  9.8699,  -9.9683],\n",
      "          [ 10.0375,  -9.7983]]],\n",
      "\n",
      "\n",
      "        [[[-10.2436,   9.9019],\n",
      "          [  9.7208,  -9.9097]],\n",
      "\n",
      "         [[-10.2628, -10.1466],\n",
      "          [-10.1280, -10.0221]],\n",
      "\n",
      "         [[ 10.2268,   9.8333],\n",
      "          [  9.8010,   9.7777]]],\n",
      "\n",
      "\n",
      "        [[[-10.2615,  10.0061],\n",
      "          [ -9.8998, -10.2023]],\n",
      "\n",
      "         [[  9.7293,   9.9554],\n",
      "          [  9.8063, -10.0933]],\n",
      "\n",
      "         [[ -9.7256, -10.1357],\n",
      "          [-10.0972,  10.1547]]],\n",
      "\n",
      "\n",
      "        [[[  9.8360,  -9.9556],\n",
      "          [ -9.8455, -10.1426]],\n",
      "\n",
      "         [[-10.1740,   9.8913],\n",
      "          [ -9.9382,  10.0483]],\n",
      "\n",
      "         [[-10.2545,  10.2032],\n",
      "          [-10.2771,   9.7853]]],\n",
      "\n",
      "\n",
      "        [[[-10.2595,  10.0740],\n",
      "          [ 10.2646, -10.1591]],\n",
      "\n",
      "         [[ -9.9727,  10.2046],\n",
      "          [-10.1792,  -9.8544]],\n",
      "\n",
      "         [[-10.0097,   9.7746],\n",
      "          [-10.1782,   9.7221]]]], requires_grad=True)\n",
      "after step Parameter containing:\n",
      "tensor([ 9.8993,  9.7754, -9.9733,  9.7227, 10.2105, -9.9490],\n",
      "       requires_grad=True)\n",
      "after step Parameter containing:\n",
      "tensor([[ 10.2026,  10.1155,   9.8335,  10.1200, -10.1522,  -9.9979,  10.0332,\n",
      "         -10.0943,  -9.9705, -10.0433,  10.1561,  10.1407, -10.0438,  10.0247,\n",
      "           9.8613,  -9.8601, -10.0734, -10.0871, -10.0826,   9.9322,  10.1839,\n",
      "          -9.8078, -10.1931,   9.8547],\n",
      "        [-10.0798, -10.1155,  -9.8494,  -9.9546,  10.0710,  10.1121,  -9.9441,\n",
      "           9.8349,   9.8067,   9.8207, -10.1649,  -9.8066,   9.8786,  -9.9108,\n",
      "          -9.9295,  10.0754,   9.9770,   9.8376,  10.1681, -10.1807, -10.1192,\n",
      "           9.9389,  10.0640, -10.0926]], requires_grad=True)\n",
      "after step Parameter containing:\n",
      "tensor([-10.0416,  10.0071], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in simple_dogcat.parameters():\n",
    "    print('after step', param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a1c34",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "962fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feat_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(in_features=6400, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=1000)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        feat = self.feat_extractor(input)\n",
    "        emb = feat.reshape((-1, 6400))\n",
    "        logits = self.pred(emb)\n",
    "        return logits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4ba7168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((4, 3, 224, 224))\n",
    "alex = AlexNet()\n",
    "logits = alex(input)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "0053f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6400])\n"
     ]
    }
   ],
   "source": [
    "reshape_out = out.reshape((4, -1))\n",
    "print(reshape_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "71ba848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "inputs = torch.randn((4, 3, 224, 224))\n",
    "target = torch.tensor([312, 1, 245, 42], dtype=int)\n",
    "\n",
    "# loss\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "29e49b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim\n",
    "adam = torch.optim.Adam(alex.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "373c657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three steps\n",
    "adam.zero_grad()\n",
    "# forward\n",
    "logits = alex(inputs)\n",
    "# backward\n",
    "loss = loss_fn(logits, target)\n",
    "loss.backward()\n",
    "# update\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataclass, dataloader, collate_fn\n",
    "# Model\n",
    "# input <- dataloader\n",
    "# model <- input\n",
    "# for input, target in dataloader:\n",
    "#   adam.zero_grad()\n",
    "#   logits = model(input)\n",
    "#   loss = loss_fn(logits, target)\n",
    "#   loss.backward()\n",
    "#   adam.step()\n",
    "\n",
    "# learning schedule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
